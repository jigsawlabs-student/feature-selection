{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by loading our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/jigsawlabs-student/feature-selection/master/listings_train_df.csv\"\n",
    "\n",
    "train_validate_df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can separate our feature and target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['price']\n",
    "X = train_validate_df.drop(columns = target_cols)\n",
    "y = train_validate_df['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And split our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X, y, random_state = 1, test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14361, 322), (3591, 322))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_validate.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.542429555631625"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eli5.sklearn import PermutationImportance\n",
    "import eli5\n",
    "\n",
    "perm = PermutationImportance(model).fit(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eli5.explain_weights_df(perm, feature_names = list(X_train.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Permutation Importance Works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's talk about how `eli5` calculates the scores above.  The concept is to remove each of the features and see the reduction in scores.  For example, let's try to drop the `first_reviewElapsed` feature and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_removed = X_validate.drop(columns = ['first_reviewElapsed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Comment and uncomment the line below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.score(X_val_removed, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we can't simply score our model with a reduced dataset.  So instead we do the next best thing.  Instead of removing the feature all together, we shuffle the feature, and then rescore the model.  If the score drops a lot, then the feature must have been significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On with the show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from our below scoring that a lot of the features are repeats of each other.  That is, when `last_reviewYear_is_na` we know that `last_reviewMonth_is_na` as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>weight</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>first_reviewElapsed</td>\n",
       "      <td>3.356578e+07</td>\n",
       "      <td>233362.828339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>last_reviewElapsed</td>\n",
       "      <td>2.847423e+07</td>\n",
       "      <td>341312.429978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>last_reviewDayofyear_is_na</td>\n",
       "      <td>7.869540e+05</td>\n",
       "      <td>18947.061155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>last_reviewDay_is_na</td>\n",
       "      <td>7.825373e+05</td>\n",
       "      <td>15185.248973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>last_reviewYear_is_na</td>\n",
       "      <td>7.801670e+05</td>\n",
       "      <td>9295.946614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>last_reviewMonth_is_na</td>\n",
       "      <td>7.748612e+05</td>\n",
       "      <td>7128.549279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>last_reviewWeek_is_na</td>\n",
       "      <td>7.745553e+05</td>\n",
       "      <td>10930.451810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>last_reviewDayofweek_is_na</td>\n",
       "      <td>7.707310e+05</td>\n",
       "      <td>6016.109522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>first_reviewDayofweek_is_na</td>\n",
       "      <td>6.884379e+05</td>\n",
       "      <td>6846.013720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>reviews_per_month_is_na</td>\n",
       "      <td>6.879067e+05</td>\n",
       "      <td>9095.983871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feature        weight            std\n",
       "0          first_reviewElapsed  3.356578e+07  233362.828339\n",
       "1           last_reviewElapsed  2.847423e+07  341312.429978\n",
       "2   last_reviewDayofyear_is_na  7.869540e+05   18947.061155\n",
       "3         last_reviewDay_is_na  7.825373e+05   15185.248973\n",
       "4        last_reviewYear_is_na  7.801670e+05    9295.946614\n",
       "5       last_reviewMonth_is_na  7.748612e+05    7128.549279\n",
       "6        last_reviewWeek_is_na  7.745553e+05   10930.451810\n",
       "7   last_reviewDayofweek_is_na  7.707310e+05    6016.109522\n",
       "8  first_reviewDayofweek_is_na  6.884379e+05    6846.013720\n",
       "9      reviews_per_month_is_na  6.879067e+05    9095.983871"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remove all of these repeated nas (except for year), to reduce multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_na_cols(df):\n",
    "    na_cols = np.array([\"Month_is_na\", \"Week_is_na\", \"Day_is_na\", \"Dayofweek_is_na\", \"Dayofyear_is_na\"])\n",
    "    to_remove = []\n",
    "    for df_col in df.columns:\n",
    "        if any(df_col.endswith(na_col)   for na_col in na_cols):\n",
    "            to_remove.append(df_col)\n",
    "    return to_remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "[Interpretable ML Book](https://christophm.github.io/interpretable-ml-book/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
